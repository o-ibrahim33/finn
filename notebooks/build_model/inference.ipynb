{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce92cf-0751-443a-9009-44fa1219c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "import onnx.numpy_helper as nph\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from detect import Detect\n",
    "from finn.util.visualization import showSrc, showInNetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25754f02-3a1f-48e5-934a-9b06b9b27626",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c61ee-6af6-43a1-aa45-c9f8f255ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 7\n",
    "anchors = np.array([[10, 13, 16, 30, 33, 23], [81, 82, 135, 169, 344, 319], [116, 90, 156, 198, 373, 326]])\n",
    "detect_head = Detect(nc, anchors,ch=[36,36,36],do_quant=False)\n",
    "detect_head.load_state_dict(torch.load(os.environ['FINN_ROOT'] + \"/notebooks/build_model/models/detect_module.pt\",map_location=torch.device('cpu')))\n",
    "detect_head.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610284a-49be-41ad-85d5-c4e7d5c569d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.util.cleanup import cleanup\n",
    "from qonnx.core.datatype import DataType\n",
    "import cv2\n",
    "\n",
    "img_path =  os.environ['FINN_ROOT'] + \"/notebooks/build_model/data/bus.jpg\"\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image_org = image.copy()\n",
    "\n",
    "image = letterbox(image, (384,640), auto=False)[0]\n",
    "input_batch = np.expand_dims(image, 0)\n",
    "image = image.astype(np.uint8)\n",
    "np.save(\"data/input.npy\",input_batch)\n",
    "input_batch = np.transpose(input_batch, (0,3,1,2))\n",
    "input_batch = input_batch.astype(np.float32)\n",
    "\n",
    "\n",
    "model_name = \"lpyoloW4A4\"\n",
    "model_path = \"/home/omar/finn/notebooks/build_model/models/{}_quant.onnx\".format(model_name)\n",
    "model_path_clean = \"/home/omar/finn/notebooks/build_model/models/{}_quant_clean.onnx\".format(model_name)\n",
    "cleanup(model_path, out_file=model_path_clean)\n",
    "\n",
    "model = ModelWrapper(model_path_clean)\n",
    "input_dict = {\"global_in\": input_batch}\n",
    "output_dict = oxe.execute_onnx(model, input_dict)\n",
    "output_model = output_dict[\"global_out\"]\n",
    "output_model = torch.from_numpy(output_model)\n",
    "\n",
    "head_out = detect_head([output_model,output_model,output_model])[0]\n",
    "head_out = head_out.detach().numpy()\n",
    "head_out = np.reshape(head_out,(1, 2160, 12))\n",
    "head_out = torch.from_numpy(head_out)\n",
    "non_max_suppression(head_out,conf_thres = 0.20, iou_thres=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ec9be-046a-4840-8e04-f09f828fb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.load(\"data/scale.npy\")\n",
    "accel_out = np.load(\"data/output.npy\")\n",
    "\n",
    "accel_out = accel_out.transpose(0,3,1,2)\n",
    "accel_out = accel_out*scale\n",
    "\n",
    "accel_out = torch.from_numpy(accel_out)\n",
    "\n",
    "head_out = detect_head([accel_out,accel_out,accel_out])[0]\n",
    "head_out = head_out.detach().numpy()\n",
    "head_out = np.reshape(head_out,(1, 2160, 12))\n",
    "head_out = torch.from_numpy(head_out)\n",
    "\n",
    "pred = non_max_suppression(head_out,conf_thres = 0.20, iou_thres=0.35)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb0ace-e236-42a3-a793-81e6a1179c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"person\",\n",
    "    \"bicycle\",\n",
    "    \"car\",\n",
    "    \"motorcycle\",\n",
    "    \"bus\",\n",
    "    \"train\",\n",
    "    \"truck\"\n",
    "]\n",
    "\n",
    "\n",
    "boxes_detected, class_names_detected, probs_detected = [], [], []\n",
    "print(pred)\n",
    "# Process predictions\n",
    "for i, det in enumerate(pred):  # per image\n",
    "    if len(det):\n",
    "        # Rescale boxes from img_size to im0 size\n",
    "        det[:, :4] = scale_coords(image.shape, det[:, :4], image_org.shape).round()\n",
    "        # Print results\n",
    "        for c in np.unique(det[:, -1]):\n",
    "            n = (det[:, -1] == c).sum()  # detections per class\n",
    "            print(f\"{n} {names[int(c)]}\")  # add to string\n",
    "        # Write results\n",
    "        for *xyxy, conf, cls in reversed(det):\n",
    "            c = int(cls)  # integer class\n",
    "            label = f'{names[c]} {conf:.2f}'\n",
    "            boxes_detected.append(xyxy)\n",
    "            class_names_detected.append(names[c])\n",
    "            probs_detected.append(conf)\n",
    "\n",
    "\n",
    "image_boxes = visualize_boxes(image_org, boxes_detected, class_names_detected, probs_detected)\n",
    "cv2.imwrite(\"data/output.jpg\", cv2.cvtColor(image_boxes, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.imshow(image_boxes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
